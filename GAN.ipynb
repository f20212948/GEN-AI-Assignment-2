{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\miniconda3\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(\n",
    "    train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "# Normalize the images to [-1, 1]\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(dim,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    # Note: None is the batch size\n",
    "    model.add(layers.Conv2DTranspose(\n",
    "        256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(\n",
    "        128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(\n",
    "        64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2),\n",
    "              padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                            input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "tf.Tensor([[-0.00013288]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eecabe4550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# noise = tf.random.normal([1, 64])\n",
    "# generator = make_generator_model(64)\n",
    "# discriminator = make_discriminator_model()\n",
    "# generated_image = generator(noise, training=False)\n",
    "# print(generated_image.shape)\n",
    "# decision = discriminator(generated_image)\n",
    "\n",
    "\n",
    "# print(decision)\n",
    "# plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\tdef __init__(self, gen,dis, g_opt,d_opt,dim):\n",
    "\t\tself.gen = gen\n",
    "\t\tself.dis =dis\n",
    "\t\tself.g_opt = g_opt\n",
    "\t\tself.d_opt = d_opt\n",
    "\t\tself.dim =dim\n",
    "   \n",
    "\n",
    "\t@tf.function\n",
    "\tdef train_step(self,images):\n",
    "\t\tnoise = tf.random.normal([BATCH_SIZE, self.dim])\n",
    "\n",
    "\t\twith tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "\t\t\tgenerated_images = self.gen(noise, training=True)\n",
    "\n",
    "\t\t\treal_output = self.dis(images, training=True)\n",
    "\t\t\tfake_output = self.dis(generated_images, training=True)\n",
    "\n",
    "\t\t\tgen_loss = generator_loss(fake_output)\n",
    "\t\t\tdisc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "\t\tgradients_of_generator = gen_tape.gradient(\n",
    "\t\t\tgen_loss, self.gen.trainable_variables)\n",
    "\t\tgradients_of_discriminator = disc_tape.gradient(\n",
    "\t\t\tdisc_loss, self.dis.trainable_variables)\n",
    "\n",
    "\t\tself.g_opt.apply_gradients(\n",
    "\t\t\tzip(gradients_of_generator, self.gen.trainable_variables))\n",
    "\t\tself.d_opt.apply_gradients(\n",
    "\t\t\tzip(gradients_of_discriminator, self.dis.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input,dim):\n",
    "\tpredictions = model(test_input, training=False)\n",
    "\tfig = plt.figure(figsize=(10, 10))\n",
    "\tfor i in range(predictions.shape[0]):\n",
    "\t\tplt.subplot(1, 5, i+1)\n",
    "\t\tplt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "\t\tplt.axis('off')\n",
    "\tplt.savefig('image_at_epoch_{:04d}_{:02d}.png'.format(epoch,dim))\n",
    "\tplt.show()\n",
    "\n",
    "def train(dataset, epochs,dim,gen,dis,d_opt,g_opt):\n",
    "\tt = Trainer(gen,dis,g_opt,d_opt,dim)\n",
    "\tseed = tf.random.normal([5, dim])\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tstart = time.time()\n",
    "\t\tfor image_batch in dataset:\n",
    "\t\t\tt.train_step(image_batch)\n",
    "\t\t# Produce images for the GIF as you go\n",
    "\t\tdisplay.clear_output(wait=True)\n",
    "\t\tgenerate_and_save_images(gen,\n",
    "\t\t\t\t\t\t\t\tepoch + 1,\n",
    "\t\t\t\t\t\t\t\tseed,dim)\n",
    "\n",
    "\t\tprint('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "\tdisplay.clear_output(wait=True)\n",
    "\tgenerate_and_save_images(gen,\n",
    "\t\t\t\t\t\t\tepochs,\n",
    "\t\t\t\t\t\t\tseed,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vansh\\miniconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\vansh\\miniconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m discriminator_optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m      9\u001b[0m seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([num_examples, dim])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdiscriminator_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgenerator_optimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs, dim, gen, dis, d_opt, g_opt)\u001b[0m\n\u001b[0;32m     16\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m---> 18\u001b[0m \t\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Produce images for the GIF as you go\u001b[39;00m\n\u001b[0;32m     20\u001b[0m display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "num_examples = 5\n",
    "\n",
    "for dim in [2,4,8,16,32,64]:\n",
    "\tgenerator = make_generator_model(dim)\n",
    "\tdiscriminator = make_discriminator_model()\n",
    "\tgenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\tdiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\tseed = tf.random.normal([num_examples, dim])\n",
    "\ttrain(train_dataset, EPOCHS,dim,generator,discriminator,discriminator_optimizer,generator_optimizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(latent_dim):\n",
    "\tanim_file = 'GAN{:d}.gif'.format(latent_dim)\n",
    "\twith imageio.get_writer(anim_file, mode='I') as writer:\n",
    "\t\tfilenames = ['./image_at_epoch_{:04d}_{:02d}.png'.format(\n",
    "\t\t\ti, latent_dim) for i in range(1, EPOCHS+1)]\n",
    "\t\t# filenames = sorted(filenames)\n",
    "\n",
    "\t\tfor filename in filenames:\n",
    "\t\t\timage = imageio.imread(filename)\n",
    "\t\t\twriter.append_data(image)\n",
    "\t\timage = imageio.imread(filename)\n",
    "\t\twriter.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
