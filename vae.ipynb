{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_probability\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "def preprocess_images(images):\n",
    "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
    "  return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
    "\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)\n",
    "train_size = 60000\n",
    "batch_size = 32\n",
    "test_size = 10000\n",
    "\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices(\n",
    "    train_images).shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(\n",
    "    test_images).shuffle(test_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    32, 3, strides=(1, 1), activation='relu'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    64, 3, strides=(1, 1), activation='relu'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    128, 3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    256, 3, strides=(2, 2), activation='relu'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(latent_dim + latent_dim)\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape((7, 7, 32)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    256, 3, strides=1, padding='same', activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    128, 3, strides=1, padding='same', activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    64, 3, strides=2, padding='same', activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    32, 3, strides=2, padding='same', activation='relu'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    1, 3, strides=1, padding='same')\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def sample(self, randinp=None):\n",
    "        # if randinp is None:\n",
    "        #     randinp = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(randinp, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "gradients = tf.Variable(0)\n",
    "loss= tf.Variable(0)\n",
    "tape = tf.Variable(0)\n",
    "class Trainer(object):\n",
    "\tdef __init__(self, model, optimizer):\n",
    "\t\tself.model = model\n",
    "\t\tself.optimizer = optimizer\n",
    "\n",
    "\t@tf.function\n",
    "\tdef train_step(self,x):\n",
    "\t\twith tf.GradientTape() as tape:\n",
    "\t\t\tloss = compute_loss(self.model, x)\n",
    "\t\tgradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "\t\tself.optimizer.apply_gradients(\n",
    "\t\t\tzip(gradients, self.model.trainable_variables))\n",
    "\t\treturn gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# random_vector_for_generation = tf.random.normal(\n",
    "#     shape=[5, 16])\n",
    "# model = VAE(16)\n",
    "# # trainer = Trainer(model, optimizer)\n",
    "# p = model.encode(train_images[0:10])\n",
    "# print(p[0].shape, p[1].shape)\n",
    "# predictions = model.sample(random_vector_for_generation)\n",
    "# for i in range(predictions.shape[0]):\n",
    "# \tplt.subplot(1, 5, i + 1)\n",
    "# \tplt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "# \tplt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "num_examples_to_generate = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, latent_dim):\n",
    "\tpredictions = model.sample(random_vector_for_generation)\n",
    "\tfig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "\tfor i in range(predictions.shape[0]):\n",
    "\t\tplt.subplot(1, 5, i + 1 )\n",
    "\t\tplt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "\t\tplt.axis('off')\n",
    "\n",
    "\t# tight_layout minimizes the overlap between 2 sub-plots\n",
    "\tplt.savefig('image_at_epoch_{:04d}_dim{:02d}.png'.format(epoch,latent_dim))\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert batch_size >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "    test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(latent_dim):\n",
    "\tanim_file = 'vae{:d}.gif'.format(latent_dim)\n",
    "\twith imageio.get_writer(anim_file, mode='I') as writer:\n",
    "\t\tfilenames = ['image_at_epoch_{:04d}_dim{:02d}.png'.format(i,latent_dim) for i in range(0, epochs+1)]\n",
    "\t\t# filenames = sorted(filenames)\n",
    "\t\tfor filename in filenames:\n",
    "\t\t\timage = imageio.imread(filename)\n",
    "\t\t\twriter.append_data(image)\n",
    "\t\timage = imageio.imread(filename)\n",
    "\t\twriter.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Test set ELBO: -155.15269470214844, time elapse for current epoch: 102.57766151428223,dim:2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_x \u001b[38;5;129;01min\u001b[39;00m train_dataset:\n\u001b[1;32m---> 12\u001b[0m \t\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMean()\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\vansh\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\tfor latent_dim in [2,4,8,16,32,64]:\n",
    "\t\trandom_vector_for_generation = tf.random.normal(shape=[num_examples_to_generate, latent_dim])\n",
    "\t\tmodel = VAE(latent_dim)\n",
    "\t\toptimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\t\toptimizer.build(model.trainable_variables)\n",
    "\t\ttrain=Trainer(model, optimizer)\n",
    "\t\tgenerate_and_save_images(model, 0, latent_dim)\n",
    "\t\tfor epoch in range(1, epochs + 1):\n",
    "\t\t\tstart_time = time.time()\n",
    "\t\t\tfor train_x in train_dataset:\n",
    "\t\t\t\ttrain.train_step(train_x)\n",
    "\t\t\tend_time = time.time()\n",
    "\n",
    "\t\t\tloss = tf.keras.metrics.Mean()\n",
    "\t\t\tfor test_x in test_dataset:\n",
    "\t\t\t\tloss(compute_loss(model, test_x))\n",
    "\t\t\telbo = -loss.result()\n",
    "\t\t\tdisplay.clear_output(wait=False)\n",
    "\t\t\tprint('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {},dim:{}'\n",
    "\t\t\t\t\t.format(epoch, elbo, end_time - start_time,latent_dim))\n",
    "\t\t\tgenerate_and_save_images(model, epoch, latent_dim)\n",
    "\t\tmake_gif(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
